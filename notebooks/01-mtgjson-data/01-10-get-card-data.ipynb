{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab MTGJSON Card Data\n",
    "\n",
    "Here I will download and clean the data for MTG cards.\n",
    "\n",
    "First we will download the data from [MTGJSON](https://mtgjson.com/downloads/all-files/).  The `AllPrintings` card data comes in various formats, such as json, sql, csv, and parquet.\n",
    "\n",
    "I will use the [parquet format](https://parquet.apache.org/), since that is the most performant format for data analysis.  It has high compression, fast load times, and can query directly on disk.  This minimizes both disk space and memory usage.\n",
    "https://mtgjson.com/api/v5/AllPrintingsParquetFiles.tar.gz\n",
    "\n",
    "The following code downloads and decompresses the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_MTGJSON = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operating system: Windows\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import platform\n",
    "from datetime import datetime\n",
    "\n",
    "# Determine the operating system\n",
    "os_name = platform.system()\n",
    "print(f\"Operating system: {os_name}\")\n",
    "\n",
    "# Define paths and file names\n",
    "save_path = pathlib.Path(\"../../data/raw/mtgjson\")\n",
    "file_base = \"AllPrintingsParquetFiles\"  # extension added later\n",
    "file_ext = \"tar.gz\" if os_name == \"Linux\" else \"zip\"\n",
    "file = f\"{file_base}.{file_ext}\"\n",
    "url = f\"https://mtgjson.com/api/v5/{file}\"\n",
    "filepath = save_path / file\n",
    "final_path = save_path / file_base\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(save_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping download of data\n"
     ]
    }
   ],
   "source": [
    "if DOWNLOAD_MTGJSON:\n",
    "    print(\"Downloading Data\")\n",
    "    print(f\"Starting datetime: {datetime.now()}\")\n",
    "\n",
    "    if os_name == \"Linux\":\n",
    "        # Linux commands\n",
    "        os.system(f\"wget -P {save_path} --progress=dot:giga {url}\")\n",
    "        os.system(f\"tar -xzf {filepath} -C {save_path}\")\n",
    "        os.system(f\"rm {filepath}\")\n",
    "        size = os.system(f\"du -sh {save_path}\")\n",
    "    elif os_name == \"Windows\":\n",
    "        # Windows commands (using PowerShell)\n",
    "        os.system(f\"powershell Invoke-WebRequest -Uri {url} -OutFile {filepath}\")\n",
    "        os.system(f\"powershell Expand-Archive -Path {filepath} -DestinationPath {save_path / file_base}\")\n",
    "        os.system(f\"powershell Remove-Item {filepath}\")\n",
    "        size = os.system(f\"powershell Get-ChildItem {save_path} | Measure-Object -Property Length -Sum | ForEach-Object {{ $_.Sum / 1MB }}\")\n",
    "    \n",
    "    print(f\"Disk usage (MB): {size}\")\n",
    "    print(f\"Finished datetime: {datetime.now()}\")\n",
    "\n",
    "else:\n",
    "    print(\"Skipping download of data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review Tables\n",
    "\n",
    "We have 18 parquet files associated with the card data, let't take a quick tour.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cardForeignData.parquet',\n",
       " 'cardIdentifiers.parquet',\n",
       " 'cardLegalities.parquet',\n",
       " 'cardPrices.parquet',\n",
       " 'cardPurchaseUrls.parquet',\n",
       " 'cardRulings.parquet',\n",
       " 'cards.parquet',\n",
       " 'meta.parquet',\n",
       " 'setBoosterContentWeights.parquet',\n",
       " 'setBoosterContents.parquet',\n",
       " 'setBoosterSheetCards.parquet',\n",
       " 'setBoosterSheets.parquet',\n",
       " 'setTranslations.parquet',\n",
       " 'sets.parquet',\n",
       " 'tokenIdentifiers.parquet',\n",
       " 'tokens.parquet']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of files\n",
    "path = final_path\n",
    "files = os.listdir(path)\n",
    "files.sort()\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Card Files:\n",
    "- `cards.parquet`: The primary file that contains card data, such as card name, mana cost, type, and text.\n",
    "- `tokens.parquet`: Same for tokens.\n",
    "- `cardForeignData.parquet`: Foreign language translations of cards.\n",
    "- `cardLegalities.parquet`: Legality of cards for various play formats.\n",
    "- `cardPrices.parquet`: Latest prices for cards on various platforms, including retail and buylist prices.\n",
    "- `cardPurchaseUrls.parquet`: URLs to various retail platforms.\n",
    "- `cardRulings.parquet`: The rulings for cards.\n",
    "\n",
    "## Set Files:\n",
    "- `sets.parquet`: Data on various released sets, such as set code (10E, OTJ...), set size, and release date.\n",
    "- `setTranslations.parquet`: Translations for set names in various languages.\n",
    "\n",
    "## Identifier Files:\n",
    "- `cardIdentifiers.parquet`: Identifiers for various MTG data platforms (TCG Collector, Scryfall, Cardmarket...).\n",
    "- `tokenIdentifiers.parquet`: Same for tokens.\n",
    "\n",
    "## Set Booster Files:\n",
    "- `setBoosterContents.parquet`: For booster packs, different mixes of sheet composition (1 theList + 13 others versus 0 theList + 14 others).\n",
    "- `setBoosterContentWeights.parquet`: The weight of each booster mix (1 in 10 boosters has theList).\n",
    "- `setBoosterSheets.parquet`: Card sheet information.\n",
    "- `setBoosterSheetCards.parquet`: Card composition of each sheet, including counts.\n",
    "\n",
    "## Meta File:\n",
    "- `meta.parquet`: Version and date for current MTGJSON build.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unique Identifiers\n",
    "\n",
    "Most of the files have a `uuid`. This is the universally unique identifier (UUID v5) for each card printing.  It is the primary key for the `cards.parquet` file and will be used to join data across tables.\n",
    "\n",
    "## MTGJSON\n",
    " - `uuid`:\n",
    "   - Reprinted card editions: Unique id\n",
    "   - [Double-faced cards](https://mtg.fandom.com/wiki/Double-faced_card) (DBC): Each face has a unique `uuid`.\n",
    "   - Foreign languages: Same Id. \n",
    "\n",
    "## WOTC Gatherer\n",
    " - `multiverseId`: The WOTC card identifier used their [Gatherer](https://gatherer.wizards.com) card database.  \n",
    "    - Reprinted card editions: Unique id\n",
    "    - Double-faced cards: Same id\n",
    "    - Foreign languages: Different id\n",
    "\n",
    "## Scryfall\n",
    " - `scryfallId`: The [Scryfall](https://scryfall.com/) uuid.  It has different rules than the MTGJSON uuid, such as faces of DFCs are not unique.\n",
    "    - Reprinted card editions: Unique id\n",
    "    - Double-faced cards: Same id.  See `scryfallCardBackId`.\n",
    "    - Foreign languages: Different id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl+bayes-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
